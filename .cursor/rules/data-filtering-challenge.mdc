---
description: 
globs: 
alwaysApply: true
---
Cursor Rule: ELMB Competition Workflow and Requirements

Rule Purpose

This rule provides a clear, stepwise workflow for participating in the ELMB (Edge Language Model Benchmark) competition, including dataset filtering, model training, merging, evaluation, and submission requirements. It ensures compliance with competition constraints and maximizes the potential for a high S score.

1. Competition Objectives
	•	Goal: Filter and submit a dataset (≤10B tokens) to fine-tune an edge language model (LM) using DoRA, aiming to maximize improvement on ELMB tasks.
	•	Tasks: Roleplay, Reasoning, Function Calling, RAG.
	•	Winning Metric: S = Simprove - Sbase (improved minus baseline performance).

2. Workflow Steps

Step 1: Data Filtering
	•	Develop a pipeline to filter raw data to ≤10B tokens.
	•	Prioritize data quality and task relevance.

Step 2: Model Training
	•	Use the provided baseline model.
	•	Train with filtered data using DoRA.
	•	Hyperparameters:
	▫	‎⁠num_train_epochs: 1⁠
	▫	‎⁠learning_rate: 1e-5⁠ (competition); ‎⁠1e-4⁠ (testing)
	▫	‎⁠lora_r: 16⁠ (competition); ‎⁠8⁠ (testing/CPU)
	▫	‎⁠batch_size: 1⁠
	▫	‎⁠device: "cuda:0"⁠ (or “cpu” if CUDA unavailable)

Step 3: Model Merging
	•	Merge DoRA adapter with the baseline model to HuggingFace format.

Step 4: Evaluation
	•	Evaluate baseline and trained models on all ELMB tasks.
	•	Calculate S score.

3. Submission Checklist
	•	Model: Trained checkpoints, adapter config/weights, merged model, README, training args.
	•	Data: Filtered dataset (<10B tokens), stats, filter config.
	•	Code: Filtering/training/merging scripts, requirements.
	•	Results: Baseline and trained model evaluation, summary, final report.

4. Validation
	•	Run ‎⁠run_complete_pipeline.sh⁠ to verify all steps (filtering, training, merging, evaluation, S score).

5. Troubleshooting
	•	OOM: Lower batch size, increase gradient accumulation.
	•	Convergence: Check learning rate, data quality.
	•	Save errors: Check directory permissions/disk space.
	•	CUDA: Use CPU fallback.
	•	Adapter: Always merge before evaluation.

6. Strategy Analogy

Approach the competition like optimizing a relay race: each step (data, training, merging, evaluation) must be precise and efficient to maximize the final score. Weakness in any segment can slow the team, so balance and targeted improvements are key.

End of Cursor Rule.
