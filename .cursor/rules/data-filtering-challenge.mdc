---
description: 
globs: 
alwaysApply: true
---
# ELMB Data Filtering Challenge - Complete Workflow Guide

## 比赛背景
1. **比赛目标**: 创建数据过滤技术并提交精炼的数据集，通过DoRA微调显著提高边缘LM在ELMB基准上的性能
2. **评估基准**: ELMB (Edge Language Model Benchmark) 包含4个任务：Roleplay, Reasoning, Function Calling, RAG
3. **获胜标准**: 最大化 S = Simprove - Sbase，其中：
   - Sbase: 基础模型在ELMB上的性能（由组织方提供）
   - Simprove: 使用过滤数据集DoRA微调后模型的性能
4. **数据限制**: 过滤数据集不超过 10B tokens

## 完整工作流程概览

### 阶段1: 数据过滤（自主开发）
```bash
# Step 1: 创建测试数据集（已验证）
python create_test_dataset.py
# 输出: data/test_dataset/test_dataset.json (220 samples for testing)

# Step 2: 大规模数据过滤（待开发）
# TBD: 实现真实的10B token数据过滤管道
# python filter_large_dataset.py --input raw_data/ --output data/filtered_dataset/ --max_tokens 10000000000
```

### 阶段2: 模型训练（使用组织方提供的基础模型）
```bash
# 方法1: GPU训练（推荐，速度快）
# 注意：如遇CUDA问题，先确保GPU环境正常
bash train.sh

# 方法2: CPU训练（已验证可用，速度较慢但稳定）
bash train_cpu.sh
# 参数设置：batch_size=1, max_steps=20, learning_rate=1e-4, lora_r=8

# 训练输出目录示例: results/YYYYMMDD_HHMMSS/dora_model_cpu/
# 包含: adapter_config.json, adapter_model.safetensors, checkpoints等
```

### 阶段3: 模型合并（必需步骤）
```bash
# 将DoRA适配器与基础模型合并，生成标准HuggingFace格式
bash scripts/run_merge_dora.sh \
    --model_name_or_path data4elm/Llama-400M-12L \
    --lora_model_path results/YYYYMMDD_HHMMSS/dora_model_cpu \
    --output_model_path results/YYYYMMDD_HHMMSS/merged_model \
    --device cpu

# 输出: 完整的合并模型，包含model.safetensors, config.json等
```

### 阶段4: ELMB评估（获得最终S score）
```bash
cd lm-evaluation-harness

# Step 1: 基础模型评估（获得Sbase）
lm_eval --model hf \
    --model_args pretrained=data4elm/Llama-400M-12L,trust_remote_code=True \
    --tasks elmb_roleplay \
    --device cpu \
    --batch_size 1 \
    --log_samples \
    --output_path ../eval_results/baseline

# Step 2: 训练模型评估（获得Simprove）
lm_eval --model hf \
    --model_args pretrained=../results/YYYYMMDD_HHMMSS/merged_model/,trust_remote_code=True \
    --tasks elmb_roleplay \
    --device cpu \
    --batch_size 1 \
    --log_samples \
    --output_path ../eval_results/trained_model

# Step 3: 计算S score
# S = Simprove - Sbase
# 示例结果：Sbase(acc=0.8), Simprove(acc=0.6) → S = -0.2
```

## 详细实现指南

### 快速开始（测试流程）
```bash
# 1. 创建测试数据集
python create_test_dataset.py

# 2. 运行CPU训练（3-5分钟完成）
bash train_cpu.sh

# 3. 合并模型
bash scripts/run_merge_dora.sh \
    --model_name_or_path data4elm/Llama-400M-12L \
    --lora_model_path results/$(ls results/ | tail -1)/dora_model_cpu \
    --output_model_path results/$(ls results/ | tail -1)/merged_model \
    --device cpu

# 4. 评估对比
cd lm-evaluation-harness
lm_eval --model hf --model_args pretrained=data4elm/Llama-400M-12L,trust_remote_code=True --tasks elmb_roleplay --device cpu --batch_size 1 --limit 5 --output_path ../eval_results/baseline_test
lm_eval --model hf --model_args pretrained=../results/$(ls ../results/ | tail -1)/merged_model/,trust_remote_code=True --tasks elmb_roleplay --device cpu --batch_size 1 --limit 5 --output_path ../eval_results/trained_test
```

### 生产环境流程（完整比赛）
```bash
# TBD: 完整的10B token数据处理流程
# 1. 大规模数据过滤
# 2. GPU训练（解决CUDA问题后）
# 3. 所有4个ELMB任务的完整评估
# 4. 超参数优化和多次实验
```

## 关键超参数要求（严格遵守）
```yaml
# 训练超参数（不可更改）
num_train_epochs: 1
learning_rate: 1e-5  # 注意：测试时用1e-4，正式比赛用1e-5
lora_r: 16          # 注意：CPU测试时用8，正式比赛用16

# 评估超参数（确保一致性）
batch_size: 1
device: "cuda:0"    # 如果CUDA可用，否则用"cpu"
tasks: "elmb_functioncalling,elmb_chatrag,elmb_reasoning,elmb_roleplay"
```

### 已验证的训练配置
```yaml
# CPU训练配置（已验证可用）
block_size: 128
per_device_train_batch_size: 1
gradient_accumulation_steps: 4
lora_r: 8
max_steps: 20  # 测试用，正式训练用更多steps
learning_rate: 1e-4
```

## ELMB任务特化策略

### 1. Roleplay 任务优化（已验证）
- **数据过滤重点**: 对话质量、角色一致性、情境理解
- **训练数据**: 高质量对话数据、角色扮演场景
- **评估指标**: elmb_roleplay 的 acc_norm
- **测试结果**: Baseline acc=0.8, Trained acc=0.6 (需要优化数据质量)

### 2. Reasoning 任务优化（待验证）
- **数据过滤重点**: 逻辑链完整性、推理步骤清晰度
- **训练数据**: 数学推理、逻辑推理、因果关系数据
- **评估指标**: elmb_reasoning 的 acc_norm
- **评估命令**: `--tasks elmb_reasoning`

### 3. Function Calling 任务优化（待验证）
- **数据过滤重点**: API调用准确性、参数正确性、工具使用
- **训练数据**: API文档、函数调用示例、工具使用指南
- **评估指标**: elmb_functioncalling 的 acc_norm
- **评估命令**: `--tasks elmb_functioncalling`

### 4. RAG 任务优化（待验证）
- **数据过滤重点**: 检索相关性、答案准确性、引用质量
- **训练数据**: 问答对、文档摘要、知识库内容
- **评估指标**: elmb_chatrag 的 acc_norm
- **评估命令**: `--tasks elmb_chatrag`

## 提交检查清单

### 必须提交的材料
1. **训练好的模型检查点**
   ```bash
   ./trained_model/
   ├── adapter_config.json      # DoRA配置
   ├── adapter_model.safetensors # DoRA权重
   ├── README.md               # 模型说明
   ├── training_args.bin       # 训练参数
   └── merged_model/           # 合并后的完整模型
       ├── config.json
       ├── model.safetensors
       └── tokenizer files
   ```

2. **过滤后的数据集**
   ```bash
   ./filtered_data/
   ├── train.jsonl            # 训练数据（<10B tokens）
   ├── data_stats.json        # 数据统计信息
   └── filter_config.json     # 过滤算法配置
   ```

3. **过滤和训练代码**
   ```bash
   ./code/
   ├── create_test_dataset.py  # 测试数据生成（已有）
   ├── data_filter.py         # 数据过滤算法（TBD）
   ├── train_cpu.sh           # CPU训练脚本（已验证）
   ├── train.sh               # GPU训练脚本（已有）
   ├── scripts/run_merge_dora.sh # 模型合并（已验证）
   ├── requirements.txt       # 依赖列表
   └── run_pipeline.sh        # 完整流程脚本
   ```

4. **ELMB评估结果**
   ```bash
   ./eval_results/
   ├── baseline/              # 基础模型结果
   ├── trained_model/         # 训练模型结果
   ├── results_summary.json   # S score汇总
   └── final_score_report.json # 最终成绩报告
   ```

### 最终验证流程
```bash
# 完整验证流程
bash run_complete_pipeline.sh

# 步骤包含：
# 1. 数据过滤验证
# 2. 模型训练验证
# 3. 模型合并验证
# 4. ELMB评估验证
# 5. S score计算验证
```

## 竞争策略建议

### 大奖策略（最大化总分）
- 平衡四个任务的数据分配（各25%）
- 开发通用性强的过滤技术
- 重点优化弱势任务的性能

### 单项奖策略（专攻特定任务）
- 将80%的数据预算投入目标任务
- 开发任务特化的过滤算法
- 深度优化单个任务的评估指标

### 创新奖策略（技术创新）  
- 开发非传统的过滤方法（如主动学习、强化学习）
- 实现可解释的过滤决策机制
- 探索多模态数据过滤技术

## 时间规划建议
- **5-6月**: 数据分析、过滤技术开发和验证
- **7月初**: 大规模数据过滤和质量检查  
- **7-8月**: 模型训练、超参数调优和性能验证
- **8月底**: 最终提交材料准备和完整性检查

## 常见问题排除

### 训练相关
- **OOM错误**: 减小batch_size，增加gradient_accumulation_steps
- **收敛问题**: 检查学习率设置，验证数据质量
- **保存错误**: 确认输出目录权限和磁盘空间
- **CUDA问题**: 使用train_cpu.sh作为备选方案

### 评估相关  
- **任务失败**: 单独运行失败任务，检查数据集可用性
- **结果异常**: 验证模型路径、提示格式匹配性
- **性能下降**: 检查基准结果来源，确认评估一致性
- **DoRA适配器加载失败**: 使用merge脚本创建标准HuggingFace格式

### 已解决的问题（经验总结）
1. **训练卡住**: 使用CPU训练脚本，减少参数规模
2. **DoRA评估失败**: 必须先合并DoRA适配器到基础模型
3. **数据集路径错误**: 确认train.sh中dataset_path设置正确
4. **wandb阻塞**: 添加`--report_to none`参数

通过遵循这个完整的工作流程，你可以从数据过滤开始，一步步完成模型训练和评估，最终获得可提交的S score结果。
