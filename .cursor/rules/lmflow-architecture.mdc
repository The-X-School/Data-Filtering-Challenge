---
description: 
globs: 
alwaysApply: true
---
---
description: "LMFlow architecture and design patterns guidance"
globs: ["src/lmflow/**/*.py", "examples/**/*.py", "configs/**/*.json", "configs/**/*.yaml"]
always: true
---

# LMFlow Architecture and Design Patterns Rules

## Core Architecture Understanding
1. **Modular Design**: LMFlow adopts a clear modular architecture, with main components including:
   - `src/lmflow/models/`: Model implementation layer, supporting various HuggingFace models
   - `src/lmflow/datasets/`: Data processing layer, supporting single-modal and multi-modal data
   - `src/lmflow/pipeline/`: Training and inference pipelines, including various fine-tuning strategies
   - `src/lmflow/utils/`: Utility functions layer

2. **Design Pattern Adherence**:
   - **Factory Pattern**: `auto_model.py`, `auto_pipeline.py`, etc., automatically select components
   - **Template Pattern**: `base_model.py`, `base_pipeline.py`, etc., base classes define interfaces
   - **Strategy Pattern**: Different fine-tuning strategies (DoRA, LoRA, DPO) can be used interchangeably

## Code Organization Principles
1. **Inheritance Hierarchy**: All models inherit from corresponding base classes, maintaining interface consistency
2. **Configuration Driven**: Control training parameters via YAML/JSON configuration files, not hardcoding
3. **Pluggability**: New fine-tuning strategies should be added as plugins without breaking existing structure

## File Naming Conventions
1. **Model files**: Named by function, e.g., `hf_decoder_model.py`, `vision2seq_model.py`
2. **Pipeline files**: Named by task type, e.g., `finetuner.py`, `evaluator.py`, `inferencer.py`
3. **Configuration files**: Under `configs/`, clearly identify purpose and parameters, e.g., `ds_config_zero3.json`

## New Feature Development Guide
1. **Adding New Models**: Create under `models/`, inheriting appropriate base classes
2. **Adding New Pipelines**: Create under `pipeline/`, implementing standard interfaces
3. **Adding New Datasets**: Extend under `datasets/`, supporting unified data formats
4. **Adding New Configurations**: Add under `configs/`, following existing naming conventions

## Performance and Scalability
1. **Distributed Support**: Default support for DeepSpeed distributed training
2. **Memory Optimization**: Support various ZeRO strategies and offloading
3. **Module Decoupling**: Loosely coupled components for easy independent testing and maintenance
