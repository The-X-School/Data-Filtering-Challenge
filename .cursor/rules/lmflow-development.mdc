---
description: 
globs: 
alwaysApply: true
---
---
description: "LMFlow development workflow and coding standards"
globs: ["src/**/*.py", "examples/**/*.py", "*.py", "requirements.txt", "pyproject.toml", "setup.py"]
always: true
---

# LMFlow Development Workflow and Coding Standards

## Project Technology Stack Understanding
1. **Core Dependencies**:
   - **PyTorch**: Deep learning framework, version >= 2.0.1
   - **HuggingFace Transformers**: Pre-trained model library, version >= 4.31.0
   - **DeepSpeed**: Distributed training framework, version >= 0.14.4
   - **PEFT**: Parameter Efficient Fine-tuning library, version = 0.15.2
   - **Accelerate**: Distributed training acceleration library, version >= 0.27.2

2. **Code Quality Tools**:
   - **Ruff**: Code checking and formatting, target version Python 3.9
   - **Configuration**: Use double quotes, 4-space indentation, support docstring formatting

## Development Environment Setup
1. **Environment Requirements**:
   - Linux OS (Ubuntu 20.04 tested)
   - Python 3.9
   - CUDA-enabled GPU (recommended)
   - MPI support (conda install mpi4py)

2. **Installation Steps**:
   ```bash
   git clone -b v0.0.9 https://github.com/OptimalScale/LMFlow.git
   cd LMFlow
   git checkout data4elm
   conda create -n lmflow python=3.9 -y
   conda activate lmflow
   conda install mpi4py
   pip install -e .
   ```

## Code Contribution Guidelines
1. **Module Development Rules**:
   - All new features must inherit from corresponding base classes
   - Use Factory Pattern to implement automatic component selection
   - Maintain interface consistency and backward compatibility

2. **File Organization**:
   - Model-related code goes into `src/lmflow/models/`
   - Data processing code goes into `src/lmflow/datasets/`
   - Training pipeline code goes into `src/lmflow/pipeline/`
   - Utility functions go into `src/lmflow/utils/`

3. **Naming Conventions**:
   - Filenames use lowercase with underscores: `hf_decoder_model.py`
   - Class names use CamelCase: `HfDecoderModel`
   - Function names use lowercase with underscores: `load_model`
   - Constants use uppercase with underscores: `DEFAULT_CONFIG`

## Configuration File Management
1. **Training Configuration**:
   - DeepSpeed configuration files go into `configs/ds_config_*.json`
   - Accelerate configuration files go into `configs/accelerate_*.yaml`
   - Iterative training configuration files go into `configs/iterative_*.yaml`

2. **Configuration Naming Conventions**:
   - Clearly identify strategy and purpose: `ds_config_zero3_for_eval.json`
   - Distinguish different hardware configurations: `accelerator_multigpu_config.yaml`

## Example Script Development
1. **examples/ Directory Standards**:
   - Each major function corresponds to an example script
   - Scripts should include complete parameter parsing and error handling
   - Provide clear usage instructions and parameter descriptions

2. **Common Example Types**:
   - `finetune.py`: Standard fine-tuning example
   - `inference.py`: Model inference example
   - `evaluation.py`: Model evaluation example
   - `*_gradio.py`: Web interface example

## Testing and Verification
1. **Code Testing**:
   - New features must include corresponding test cases
   - Use small datasets for functional verification
   - Ensure compatibility with existing features

2. **Performance Testing**:
   - Test under different hardware configurations
   - Verify memory usage and training speed
   - Check correctness of distributed training

## Documentation and Comments
1. **Code Comments**:
   - All code comments must be written in English
   - Important functions require detailed docstrings
   - Complex logic requires inline comments for explanation

2. **Configuration Documentation**:
   - Each configuration file should include parameter descriptions
   - Provide usage scenarios and applicable conditions
   - Note performance impact and resource requirements

## Version Compatibility
1. **Dependency Version Management**:
   - Clearly specify version ranges for key dependencies
   - Regularly test compatibility with the latest versions
   - Promptly update `requirements.txt`

2. **Backward Compatibility**:
   - New features must not break existing APIs
   - Deprecated features require migration guides
   - Maintain compatibility of configuration file formats

## Performance Optimization Guide
1. **Memory Optimization**:
   - Use appropriate data types (bf16, fp16)
   - Implement gradient checkpointing
   - Optimize data loading and preprocessing

2. **Computation Optimization**:
   - Support various distributed training strategies
   - Implement efficient attention mechanisms
   - Optimize model forward and backward propagation

## Error Handling Standards
1. **Exception Handling**:
   - Use clear exception types
   - Provide useful error messages
   - Add error recovery mechanisms in critical locations

2. **Logging**:
   - Use a unified logging format
   - Log key operations and parameters
   - Distinguish different levels of log information
