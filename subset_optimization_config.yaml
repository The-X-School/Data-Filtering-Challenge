# Subset-Based Bayesian Optimization Configuration for DoRA Fine-tuning

# Study Configuration
study:
  name: "subset_dora_optimization"
  n_trials: 15
  timeout: 21600  # 6 hours
  enable_pruning: true

# Model Configuration
model:
  base_model_path: "data4elm/Llama-400M-12L"
  dataset_path: "data/filtered_output"
  
  # Fixed hyperparameters (competition requirement)
  fixed_hyperparameters:
    num_train_epochs: 1
    learning_rate: 1e-5
    lora_r: 16

# Output Configuration
output:
  base_dir: "subset_optimization_results"
  models_dir: "subset_optimization_models"

# Evaluation Configuration
evaluation:
  limit: 25  # Small for faster trials
  device: "cuda:0"
  tasks:
    - "elmb_roleplay"
    - "elmb_reasoning"
    - "elmb_functioncalling"
    - "elmb_chatrag"

# Subset Optimization Configuration
subset_optimization:
  # DoRA module optimization
  optimize_target_modules: true
  min_target_modules: 3
  max_target_modules: 7
  
  # Search strategy options: "minimal", "focused", "progressive", "comprehensive"
  search_strategy: "focused"
  
  # Focus on specific task (optional)
  # Options: "elmb_roleplay", "elmb_reasoning", "elmb_functioncalling", "elmb_chatrag"
  focus_on_task: null  # Set to task name to focus optimization
  
  # Progressive refinement
  enable_progressive_refinement: false
  initial_trials_per_stage: 5
  refinement_stages: 2

# DoRA Module Groups (predefined efficient combinations)
dora_module_groups:
  # Most efficient combinations based on research
  minimal:
    - "q_proj"
    - "v_proj" 
    - "down_proj"
    
  core:
    - "q_proj"
    - "v_proj"
    - "gate_proj"
    - "down_proj"
    
  attention:
    - "q_proj"
    - "k_proj"
    - "v_proj"
    - "o_proj"
    
  mlp:
    - "gate_proj"
    - "up_proj"
    - "down_proj"
    
  extended:
    - "embed_tokens"
    - "q_proj"
    - "k_proj"
    - "v_proj"
    - "o_proj"
    - "gate_proj"
    - "up_proj"
    - "down_proj"
    
  embeddings:
    - "embed_tokens"
    - "lm_head"

# Search Space Strategies
search_strategies:
  # Minimal: Only most impactful parameters (fastest)
  minimal:
    parameters:
      - "per_device_train_batch_size"
      - "gradient_accumulation_steps"
      - "lora_alpha"
      - "block_size"
      - "warmup_steps"
    expected_trials: 8-12
    estimated_time: "2-3 hours"
  
  # Focused: Task-specific optimization (recommended)
  focused:
    parameters:
      - "per_device_train_batch_size"
      - "gradient_accumulation_steps"
      - "lora_alpha"
      - "lora_dropout"
      - "block_size"
      - "warmup_steps"
      - "weight_decay"
    expected_trials: 15-20
    estimated_time: "4-6 hours"
  
  # Progressive: Starts broad, narrows down
  progressive:
    parameters:
      - "per_device_train_batch_size"
      - "gradient_accumulation_steps"
      - "lora_alpha"
      - "lora_dropout"
      - "block_size"
      - "warmup_steps"
      - "weight_decay"
      - "lr_scheduler_type"
      - "dataloader_num_workers"
    expected_trials: 25-30
    estimated_time: "6-8 hours"
  
  # Comprehensive: All parameters (most thorough)
  comprehensive:
    parameters:
      - "per_device_train_batch_size"
      - "gradient_accumulation_steps"
      - "lora_alpha"
      - "lora_dropout"
      - "block_size"
      - "warmup_steps"
      - "weight_decay"
      - "lr_scheduler_type"
      - "dataloader_num_workers"
      - "preprocessing_num_workers"
      - "deepspeed_config"
      - "logging_steps"
      - "save_steps"
      - "validation_split_percentage"
    expected_trials: 35-50
    estimated_time: "10-16 hours"

# Task-Specific Optimization Guidelines
task_specific_optimization:
  elmb_roleplay:
    description: "Creative dialogue and role-playing scenarios"
    recommended_modules: ["q_proj", "v_proj", "gate_proj", "down_proj", "lm_head"]
    key_parameters:
      - "lora_alpha"  # Higher values for creativity
      - "lora_dropout"  # Moderate dropout for generalization
      - "block_size"  # Larger context for dialogue
    
  elmb_reasoning:
    description: "Logical reasoning and problem-solving"
    recommended_modules: ["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj"]
    key_parameters:
      - "block_size"  # Larger context for reasoning chains
      - "warmup_steps"  # Careful training for precision
      - "weight_decay"  # Regularization for stability
      
  elmb_functioncalling:
    description: "API calls and structured interactions"
    recommended_modules: ["q_proj", "v_proj", "down_proj", "lm_head"]
    key_parameters:
      - "lora_dropout"  # Lower dropout for precision
      - "per_device_train_batch_size"  # Smaller batches for stability
      - "warmup_steps"  # Gradual learning for accuracy
      
  elmb_chatrag:
    description: "Retrieval-augmented generation"
    recommended_modules: ["embed_tokens", "q_proj", "k_proj", "v_proj", "gate_proj"]
    key_parameters:
      - "block_size"  # Large context for retrieval
      - "gradient_accumulation_steps"  # Effective batch size
      - "weight_decay"  # Prevent overfitting to retrieval patterns

# Resource Management
resources:
  training_timeout: 2400  # 40 minutes per trial
  evaluation_timeout: 900  # 15 minutes per evaluation
  merge_timeout: 300  # 5 minutes per merge
  
# Advanced Options
advanced:
  cleanup_intermediate_files: true
  save_all_models: false
  enable_early_stopping: true
  parallel_evaluation: false

# Usage Examples
usage_examples:
  quick_test:
    command: "python subset_optimization.py --strategy minimal --n-trials 8"
    description: "Quick test with minimal search space"
    
  focus_on_roleplay:
    command: "python subset_optimization.py --strategy focused --focus-task elmb_roleplay --n-trials 15"
    description: "Focus optimization on roleplay task"
    
  module_optimization:
    command: "python subset_optimization.py --strategy progressive --optimize-modules --n-trials 20"
    description: "Optimize both hyperparameters and DoRA modules"
    
  cpu_mode:
    command: "python subset_optimization.py --strategy minimal --device cpu --n-trials 10"
    description: "CPU-only optimization for resource-constrained environments" 